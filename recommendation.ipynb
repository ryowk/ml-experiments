{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakatsuki/.pyenv/versions/3.9.9/lib/python3.9/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from lightfm import LightFM\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1c3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8fd9c3",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "* p: user probability\n",
    "* q: item probability\n",
    "* x: user feature\n",
    "* y: item feature\n",
    "* target probability = p * q * (1.0 - |x - y|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74179c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user = 2000\n",
    "n_item = 10000\n",
    "ps = np.random.uniform(0.0, 1.0, n_user)\n",
    "qs = np.random.uniform(0.0, 1.0, n_item)\n",
    "xs = np.random.uniform(0.0, 1.0, n_user)\n",
    "ys = np.random.uniform(0.0, 1.0, n_item)\n",
    "rs = np.outer(ps, qs) * (1.0 - np.abs(np.subtract.outer(xs, ys)))\n",
    "target = np.random.binomial(1, rs.flatten()).reshape(n_user, n_item)\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'user': i, 'item': j, 'x': xs[i], 'y': ys[j],\n",
    "        'p': ps[i], 'q': qs[j], 'target': target[i][j],\n",
    "    }\n",
    "    for (i, j) in itertools.product(range(n_user), range(n_item))\n",
    "])\n",
    "features = ['x', 'y', 'p', 'q']\n",
    "\n",
    "# used by lightfm\n",
    "user_features = np.array([[p, x] for (p, x) in zip(ps, xs)])\n",
    "item_features = np.array([[q, y] for (q, y) in zip(qs, ys)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d4f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df):\n",
    "    users = df['user'].unique()\n",
    "    auc = roc_auc_score(df['target'], df['pred'])\n",
    "    ap = average_precision_score(df['target'], df['pred'])\n",
    "    aucs = []\n",
    "    aps = []\n",
    "    for user in users:\n",
    "        tmp = df[df['user']==user]\n",
    "        if len(tmp['target'].unique()) != 2:\n",
    "            continue\n",
    "        aucs.append(roc_auc_score(tmp['target'], tmp['pred']))\n",
    "        aps.append(average_precision_score(tmp['target'], tmp['pred']))\n",
    "        \n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'mauc': np.mean(aucs),\n",
    "        'ap': ap,\n",
    "        'map': np.mean(aps),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b18412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.3\n",
    "train_sampling_ratio = 0.3\n",
    "df_train = df.query(\"user > @n_user * @test_ratio\").sample(frac=train_sampling_ratio).sort_values(by='user').reset_index(drop=True)\n",
    "df_test = df.query(\"user <= @n_user * @test_ratio\").reset_index(drop=True)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782a5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_encoding(sequence):\n",
    "    comp_seq_index, = np.concatenate(([True], sequence[1:] != sequence[:-1], [True])).nonzero()\n",
    "    return sequence[comp_seq_index[:-1]], np.ediff1d(comp_seq_index)\n",
    "\n",
    "def get_query_group(df):\n",
    "    users = df['user'].values\n",
    "    _, group = run_length_encoding(users)\n",
    "    return list(group)\n",
    "    \n",
    "# used by lightgbm lambdarank\n",
    "group_train = get_query_group(df_train)\n",
    "group_test = get_query_group(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e0f3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[features]\n",
    "X_test = df_test[features]\n",
    "y_train = df_train['target']\n",
    "y_test = df_test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198b409",
   "metadata": {},
   "source": [
    "# LightGBM (binary loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ec98c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's auc: 0.789812\tvalid_1's auc: 0.79284\n",
      "{'auc': 0.7928398537661724, 'mauc': 0.6968214668279816, 'ap': 0.43387864922580366, 'map': 0.28523645868577435}\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.001,\n",
    "    'metric': 'auc',\n",
    "    'seed': seed,\n",
    "    'verbose': 0,\n",
    "}\n",
    "model = lgb.train(\n",
    "    lgb_params, lgb_train, valid_sets=[lgb_train, lgb_eval],\n",
    "    num_boost_round=1000, callbacks=[lgb.early_stopping(10)],\n",
    ")\n",
    "df_test['pred'] = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "result_lgbm_binary = evaluate(df_test)\n",
    "print(result_lgbm_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f61bbe",
   "metadata": {},
   "source": [
    "# LightGBM (lambdarank loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3244634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's map@1: 0.362402\ttraining's map@2: 0.320586\ttraining's map@3: 0.297435\ttraining's map@4: 0.280796\ttraining's map@5: 0.27127\tvalid_1's map@1: 0.371048\tvalid_1's map@2: 0.313644\tvalid_1's map@3: 0.290996\tvalid_1's map@4: 0.276484\tvalid_1's map@5: 0.266578\n",
      "{'auc': 0.6603071639958251, 'mauc': 0.718404820304217, 'ap': 0.2919098600681591, 'map': 0.3003598531645943}\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train, group=group_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, group=group_test, reference=lgb_train)\n",
    "lgb_params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.001,\n",
    "    'metric': 'map',\n",
    "    'seed': seed,\n",
    "    'verbose': 0,\n",
    "}\n",
    "model = lgb.train(\n",
    "    lgb_params, lgb_train, valid_sets=[lgb_train, lgb_eval],\n",
    "    num_boost_round=1000, callbacks=[lgb.early_stopping(10)],\n",
    ")\n",
    "df_test['pred'] = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "result_lgbm_lambdarank = evaluate(df_test)\n",
    "print(result_lgbm_lambdarank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d834c",
   "metadata": {},
   "source": [
    "# LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e634c35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.33015735393666834, 'mauc': 0.731042048722827, 'ap': 0.11518122981098311, 'map': 0.31616077049112423}\n"
     ]
    }
   ],
   "source": [
    "mat_train = lil_matrix((n_user, n_item))\n",
    "mat_train[df_train['user'], df_train['item']] = df_train['target']\n",
    "\n",
    "model = LightFM(\n",
    "    no_components=8,\n",
    "    learning_schedule='adadelta',\n",
    "    loss='warp',\n",
    "    learning_rate=0.001,\n",
    "    random_state=seed,\n",
    ")\n",
    "model.fit(\n",
    "    mat_train,\n",
    "    user_features=csr_matrix(user_features),\n",
    "    item_features=csr_matrix(item_features),\n",
    "    epochs=100,\n",
    "    num_threads=psutil.cpu_count(logical=False),\n",
    ")\n",
    "\n",
    "df_test['pred'] = model.predict(\n",
    "    user_ids=df_test['user'].values,\n",
    "    item_ids=df_test['item'].values,\n",
    "    user_features=csr_matrix(user_features),\n",
    "    item_features=csr_matrix(item_features),\n",
    ")\n",
    "result_lightfm = evaluate(df_test)\n",
    "print(result_lightfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad7bdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>auc</th>\n",
       "      <th>mauc</th>\n",
       "      <th>ap</th>\n",
       "      <th>map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm_binary</td>\n",
       "      <td>0.792840</td>\n",
       "      <td>0.696821</td>\n",
       "      <td>0.433879</td>\n",
       "      <td>0.285236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lgbm_lambdarank</td>\n",
       "      <td>0.660307</td>\n",
       "      <td>0.718405</td>\n",
       "      <td>0.291910</td>\n",
       "      <td>0.300360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.330157</td>\n",
       "      <td>0.731042</td>\n",
       "      <td>0.115181</td>\n",
       "      <td>0.316161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name       auc      mauc        ap       map\n",
       "0      lgbm_binary  0.792840  0.696821  0.433879  0.285236\n",
       "1  lgbm_lambdarank  0.660307  0.718405  0.291910  0.300360\n",
       "2          lightfm  0.330157  0.731042  0.115181  0.316161"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lgbm_binary['name'] = 'lgbm_binary'\n",
    "result_lgbm_lambdarank['name'] = 'lgbm_lambdarank'\n",
    "result_lightfm['name'] = 'lightfm'\n",
    "df_result = pd.DataFrame(\n",
    "    [result_lgbm_binary, result_lgbm_lambdarank, result_lightfm]\n",
    ")\n",
    "df_result[['name', 'auc', 'mauc', 'ap', 'map']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1fcee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8364c30153e64a8e41dd07360d596e08d8f830a531d4b9efe2f4c7f1ee4851c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('3.9.9': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
